hunspell 한국어 데이터, 개발 정보

이 파일은 소스 파일입니다. 맞춤법 검사 기능을 사용하려면 이 소스
파일에서 빌드한 AFF 및 DIC 파일을 이용하거나 여러 가지 확장 기능을
이용하십시오.

프로젝트 정보: http://code.google.com/p/spellcheck-ko/

빌드
====

make와 Python이 설치되어 있는 환경에서 make 명령을 실행하면 hunspell이
사용하는 맞춤법 사전 데이터인 ko.aff 및 ko.dic 파일을 만들어 낸다.

DIC 파일에는 표제어 데이터가 들어 있고 AFF (affix) 파일에는 단어의 활용
정보가 들어간다. AFF 파일과 DIC 파일은 hunspell의 전신인 myspell에서도
이용하는 형식이지만 한국어 데이터는 hunspell에만 들어 있는 기능이
필요하기 때문에 hunspell에서만 동작한다.

DIC 파일과 AFF 파일의 내용은 프로그램을 통해 만들어 내기 때문에 직접
편집하지 않도록 한다. 데이터는 유니코드의 한글 자모 코드로 (U+1100)
쓰여 있기 때문에 에디터에서 직접 편집하면 의도한 대로 동작하지 않는다.

소스 프로그램
=============

데이터를 만들어 내는 소스 프로그램은 Python으로 작성되어 있고,
수정하려면 유니코드의 한글 코드, 특히 한글 자모 (U+1100,
http://unicode.org/charts/PDF/U1100.pdf 참고) 영역을 잘 알고 있어야
한다. 모든 파일은 UTF-8 인코딩으로 작성되어 있으므로 UTF-8 인코딩을
편집할 수 있는 에디터를 사용해야 한다. 코드와 데이터 전체에 걸쳐
유니코드를 사용하므로 인코딩을 바꾸면 올바르게 동작하지 않는다.

현대 한글만 지원하므로 현대 자모만 사용하고 옛한글 자모는 사용하지
않는다. 완벽함을 따진다면 옛한글 자모를 굳이 뺄 필요도 없지만, 알고리듬
처리 속도가 느려지고 어차피 중세 국어 맞춤법 검사를 구현하기도 어렵다.

인코딩 문제
-----------

편집 거리 계산 (insert/delete/replace) 알고리듬이 한글 음절 단위가
아니라 자모 단위로 동작하도록, 또 파생 규칙을 편리하게 작성할 수 있도록
내부적으로 모두 유니코드의 한글 자모 코드로 (U+1100) 처리한다.

때문에 한글 음절 (U+AC00) 코드에서 이 한글 자모 코드로 변환하고, 이
코드를 다시 한글 음절로 변환하는 유니코드 정규화 변환을 해야 하는데
AFF 파일의 ICONV 및 OCONV 키워드를 이용한다. 이 때문에 hunspell 1.2.8
이상 버전이 필요하다. AFF 파일의 크기가 커지고 메모리 사용량이 약간
부담스럽지만 향후에는 hunspell 내부에서 직접 이 코드 변환을 지원할 수도
있을 것이다.

hunspell 1.2.8 버전을 사용할 경우에도 셸에서 실행하는 hunspell
명령어에서는 자체 내장된 tokenizer에서 (문자열을 단어 단위로 구분하는
기능을 말한다) 한글 음절로 구성된 단어를 분리하지 못한다. 그래서 셸에서
hunspell 명령을 실행할 경우 맞춤법 검사가 올바르게 동작하지 않는다. 이
문제를 바로잡은 hunspell 프로그램을 설치해서 사용하거나, 아니면 한글
자모 코드로 변환한 문자열을 입력해야 한다. 셸에서 사용하는 명령어가
아니라 hunspell 라이브러리만 사용하는 다른 응용 프로그램은 tokenizer를
자체 구현하므로 이 문제가 발생하지 않는다.

사전 데이터
===========

사전 데이터는 "갈퀴" 온라인 시스템에서 만들어져서, 리뷰를 거친 단어
모음을 XML 형식으로 export해 이 소스 파일로 가져온다. 파이썬 코드가
이 데이터를 읽어 DIC 파일을 만든다.

대략의 사전 형식:

  <?xml version="1.0"?>
  <entries>
    <Entry>
      <word>홈런</word>
      <pos>명사</pos>
      <props>가산명사</props>
      <etym>homerun</etym>
      <comment>야구</comment>
    </Entry>
  </entries>

갈퀴 데이터베이스에서는 과거에 입력한 사전이 모두 기록으로 남아 있다.
하지만 이 소스 코드에는 갈퀴 데이터베이스에서 현재 유효한 사전 엔트리만
들어 있다.

수동 입력한 데이터만 사용
-------------------------

맞춤법 검사의 성능은 단어 데이터의 완성도에 크게 좌우된다. 그래서
외부에 공개되어 있는 다른 단어 데이터를 입력하면 간단히 맞춤법 검사의
품질을 높일 수 있지 않을까 생각하기 쉽다.

하지만 외부 데이터는 라이선스 논란의 여지가 있으므로 사용하지 않고,
바닥부터 시작해서 직접 수동으로 입력한 데이터만 사용하도록 한다.
현재까지 조사해 봤지만 자유로운 라이선스로 배포했을 때 저작권 문제나
라이선스 충돌을 일으키지 않는다고 100% 확신할 수 있는 단어 데이터는
찾을 수 없었다. 단어 정보와 같은 종류의 보편적인 데이터는 독창적인
저작물이 아니라 일반적인 사실의 모음이므로 저작권을 주장할 수 없다는
해석도 있지만, 조금의 논란이라도 발생할 가능성이 있다면 피해 가려고
한다. 만약 독점적인 라이선스가 있거나 출처가 명확하지 않은 외부의
데이터를 변환해 사용한다면 매번 이러한 논란에 시달릴 것이고 실질적으로
리눅스 배포판 등 다른 소프트웨어 패키지에 포함되지 못한다.

공개된 개발 커뮤니티의 힘으로 사전 데이터를 바닥부터 만들어 가는 작업은
쉽지 않지만 충분히 가능한 일이다. 처음 시작할 때도 일상생활에 보이는
단어를 입력하거나, 웹 문서에서 누락된 단어를 하나씩 입력하는 방법으로
단기간에 꽤 쓸 만한 단어 모음을 만들 수 있었고, 지속적으로 관리하면
충분히 완성도 높은 데이터가 만들어질 것이다. 핀란드어, 덴마크어,
노르웨이어 등 언어 사용자가 한국어보다 훨씬 적은 다른 언어의 맞춤법
사전도 참여하는 사람들의 힘으로 품질 높은 데이터를 축적했다.

단어 품사
---------

"명사", "대명사", "동사", "형용사", "감탄사", "관형사", "부사"

  일반 품사

  9품사 중에서 수사와 조사는 따로 처리하므로 단어 데이터에 따로 쓰지
  않는다.

"특수:금지어"

  특별히 틀린 단어로 취급할 단어. 

  사전에 기재되어 있지 않으면 틀린 단어로 취급하기 때문에 일상적으로
  틀리는 단어를 여기에 기입할 필요는 없고, 사전에 있는 다른 단어의
  활용을 통해 파생될 수 있지만 예외적으로 틀린 단어이거나, 거의 쓰지
  않는 단어이고 잘못 썼을 가능성이 훨씬 높은 단어의 경우 이렇게 쓴다.
  (예를 들어, "화일"은 "화"+"이다"+"-ㄹ"이라고 생각할 수도 있지만,
  "파일"을 잘못 쓰는 경우가 대부분이므로 금지어로 취급한다.)

"특수:복수접미사", "특수:숫자", "특수:알파벳", "특수:수:<자리수>"

  내부적으로 접미어, 합성어를 위해 사용. 새로 추가할 일 없음.

단어 속성
---------

"가산명사"

  -들 접미어를 붙일 수 있는 명사

"단위명사"

  수량을 나타내는 명사, 아라비아 숫자 뒤에 붙여 쓰기 가능

"ㄷ불규칙", "ㅂ불규칙", "ㅅ불규칙", "ㅎ불규칙", "거라불규칙",
"너라불규칙", "러불규칙", "르불규칙", "우불규칙", "으불규칙"

  불규칙 용언 활용

  여 불규칙 활용 (~하다 형태의 용언), 리을 불규칙 (리을 탈락) 활용은
  따로 쓰지 않는다. (별도로 쓰지 않아도 알 수 있으므로.)

"보조용언:-어"

  다른 용언의 -어 형태 뒤에 붙여 쓸 수 있는 보조용언

"보조용언:-을"

  다른 용언의 -을 형태 뒤에 붙여 쓸 수 있는 보조용언. 수가 한정되어
  있으므로 새로 추가할 일 없음. "만하다", "법하다", "듯싶다",
  "듯하다", "뻔하다", "성싶다"

"보조용언:-은"

  다른 용언의 -은 형태 뒤에 붙여 쓸 수 있는 보조용언. 수가 한정되어
  있으므로 새로 추가할 일 없음. "양하다", "체하다", "듯싶다",
  "듯하다",
